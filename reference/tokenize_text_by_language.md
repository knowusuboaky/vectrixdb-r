# Language-aware tokenizer used across embedders and keyword search

Language-aware tokenizer used across embedders and keyword search

## Usage

``` r
tokenize_text_by_language(text, language = "en", remove_stopwords = FALSE)
```

## Arguments

- text:

  Input text

- language:

  "en" or "ml"

- remove_stopwords:

  Remove English stopwords when language is "en"

## Value

Character vector of tokens
